{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>I feel that it was better I dieAm happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>Why do I get hallucinations?</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>I am stresseed due to lack of financial suppor...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>Why is life important?</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>How could I be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V6VSDJ5I</td>\n",
       "      <td>What are the effects of depression to ones health</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9736J4UE</td>\n",
       "      <td>Why is everything so hard to deal with in this...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AY8L479Y</td>\n",
       "      <td>I feel emotionally overwhelmed</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OSFJV5EC</td>\n",
       "      <td>How to manage taking alcohol?</td>\n",
       "      <td>Alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U4SGUGGM</td>\n",
       "      <td>Is heaven open for us who smoke bhang?</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            I feel that it was better I dieAm happy  Depression\n",
       "1  9JDAGUV3                       Why do I get hallucinations?       Drugs\n",
       "2  419WR1LQ  I am stresseed due to lack of financial suppor...  Depression\n",
       "3  6UY7DX6Q                             Why is life important?     Suicide\n",
       "4  FYC0FTFB  How could I be helped to go through the depres...  Depression\n",
       "5  V6VSDJ5I  What are the effects of depression to ones health  Depression\n",
       "6  9736J4UE  Why is everything so hard to deal with in this...  Depression\n",
       "7  AY8L479Y                    I feel emotionally overwhelmed   Depression\n",
       "8  OSFJV5EC                      How to manage taking alcohol?     Alcohol\n",
       "9  U4SGUGGM             Is heaven open for us who smoke bhang?       Drugs"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"F:\\Challenge\\NeedsRights_Kenya\\data\\train.csv\", sep=\",\")\n",
    "df = df[pd.notnull(df['label'])]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Depression</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drugs</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suicide</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  count\n",
       "0     Alcohol    140\n",
       "1  Depression    352\n",
       "2       Drugs     58\n",
       "3     Suicide     66"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.groupby(\"label\", sort='count').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['Alcohol','Depression','Drugs','Suicide']\n",
    "plt.figure(figsize=(10,4))\n",
    "df.label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are not well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = df[df.index == index][['text', 'label']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Tag:', example[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look a few post and tag pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to survive without money?\n",
      "Tag: Depression\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How will I stop? What addiction means.\n",
      "Tag: Alcohol\n"
     ]
    }
   ],
   "source": [
    "print_plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text need to be cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survive without money\n",
      "Tag: Depression\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>feel better dieam happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>stresseed due lack financial support school</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>could helped go depression</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V6VSDJ5I</td>\n",
       "      <td>effects depression ones health</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9736J4UE</td>\n",
       "      <td>everything hard deal life</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AY8L479Y</td>\n",
       "      <td>feel emotionally overwhelmed</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OSFJV5EC</td>\n",
       "      <td>manage taking alcohol</td>\n",
       "      <td>Alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U4SGUGGM</td>\n",
       "      <td>heaven open us smoke bhang</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         text       label\n",
       "0  SUAVK39Z                      feel better dieam happy  Depression\n",
       "1  9JDAGUV3                           get hallucinations       Drugs\n",
       "2  419WR1LQ  stresseed due lack financial support school  Depression\n",
       "3  6UY7DX6Q                               life important     Suicide\n",
       "4  FYC0FTFB                   could helped go depression  Depression\n",
       "5  V6VSDJ5I               effects depression ones health  Depression\n",
       "6  9736J4UE                    everything hard deal life  Depression\n",
       "7  AY8L479Y                 feel emotionally overwhelmed  Depression\n",
       "8  OSFJV5EC                        manage taking alcohol     Alcohol\n",
       "9  U4SGUGGM                   heaven open us smoke bhang       Drugs"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "x = df\n",
    "freq=pd.Series(''.join(x['text']).split()).value_counts()\n",
    "freq_remove =freq[freq==1]\n",
    "f = lambda x:\" \".join(x for x in x.split() if x not in freq_remove)\n",
    "x['text'] = x['text'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = set(['les','le'])\n",
    "\n",
    "def clean_text_2(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "    \"\"\"\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dieam happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stresseed due to lack of financial suppor...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V6VSDJ5I</td>\n",
       "      <td>what are the effects of depression to ones health</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9736J4UE</td>\n",
       "      <td>why is everything so hard to deal with in this...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AY8L479Y</td>\n",
       "      <td>i feel emotionally overwhelmed</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OSFJV5EC</td>\n",
       "      <td>how to manage taking alcohol</td>\n",
       "      <td>Alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U4SGUGGM</td>\n",
       "      <td>is heaven open for us who smoke bhang</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dieam happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stresseed due to lack of financial suppor...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression\n",
       "5  V6VSDJ5I  what are the effects of depression to ones health  Depression\n",
       "6  9736J4UE  why is everything so hard to deal with in this...  Depression\n",
       "7  AY8L479Y                    i feel emotionally overwhelmed   Depression\n",
       "8  OSFJV5EC                       how to manage taking alcohol     Alcohol\n",
       "9  U4SGUGGM              is heaven open for us who smoke bhang       Drugs"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# my function splite\n",
    "def split_balanced(data, target, test_size=0.2):\n",
    "\n",
    "    classes = np.unique(target)\n",
    "    # can give test_size as fraction of input data size of number of samples\n",
    "    if test_size<1:\n",
    "        n_test = np.round(len(target)*test_size)\n",
    "    else:\n",
    "        n_test = test_size\n",
    "        \n",
    "    n_train = max(0,len(target)-n_test)\n",
    "    n_train_per_class = max(1,int(np.floor(n_train/len(classes))))\n",
    "    n_test_per_class = max(1,int(np.floor(n_test/len(classes))))\n",
    "\n",
    "    ixs = []\n",
    "    for cl in classes:\n",
    "        if (n_train_per_class+n_test_per_class) > np.sum(target==cl):\n",
    "            # if data has too few samples for this class, do upsampling\n",
    "            # split the data to training and testing before sampling so data points won't be\n",
    "            #  shared among training and test data\n",
    "            splitix = int(np.ceil(n_train_per_class/(n_train_per_class+n_test_per_class)*np.sum(target==cl)))\n",
    "            ixs.append(np.r_[np.random.choice(np.nonzero(target==cl)[0][:splitix], n_train_per_class),\n",
    "                np.random.choice(np.nonzero(target==cl)[0][splitix:], n_test_per_class)])\n",
    "        else:\n",
    "            ixs.append(np.random.choice(np.nonzero(target==cl)[0], n_train_per_class+n_test_per_class,\n",
    "                replace=False))\n",
    "\n",
    "    # take same num of samples from all classes\n",
    "    ix_train = np.concatenate([x[:n_train_per_class] for x in ixs])\n",
    "    ix_test = np.concatenate([x[n_train_per_class:(n_train_per_class+n_test_per_class)] for x in ixs])\n",
    "\n",
    "    X_train = data[ix_train]\n",
    "    X_test = data[ix_test]\n",
    "    y_train = target[ix_train]\n",
    "    y_test = target[ix_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# apply function\n",
    "X = df.text\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_balanced(X , y,test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "y_test.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Alcohol       0.78      0.81      0.80        43\n",
      "  Depression       0.70      0.98      0.82        95\n",
      "       Drugs       1.00      0.23      0.37        22\n",
      "     Suicide       1.00      0.08      0.15        25\n",
      "\n",
      "    accuracy                           0.73       185\n",
      "   macro avg       0.87      0.53      0.53       185\n",
      "weighted avg       0.79      0.73      0.67       185\n",
      "\n",
      "Wall time: 28.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42491773, 0.19668012, 0.14835865, 0.23004349],\n",
       "       [0.03142368, 0.87989257, 0.03053051, 0.05815323],\n",
       "       [0.02660526, 0.91490384, 0.02659604, 0.03189486],\n",
       "       ...,\n",
       "       [0.21301781, 0.17995854, 0.12158039, 0.48544326],\n",
       "       [0.11273976, 0.10876568, 0.66798702, 0.11050754],\n",
       "       [0.50693092, 0.20858825, 0.07007461, 0.21440623]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"F:\\Challenge\\NeedsRights_Kenya\\data\\Test.csv\", sep=\",\")\n",
    "y_prob = nb.predict_proba(test['text'])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.196680</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.230043</td>\n",
       "      <td>0.148359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>0.058153</td>\n",
       "      <td>0.030531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.914904</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>0.031895</td>\n",
       "      <td>0.026596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Depression   Alcohol   Suicide     Drugs\n",
       "0  02V56KMO    0.196680  0.424918  0.230043  0.148359\n",
       "1  03BMGTOK    0.879893  0.031424  0.058153  0.030531\n",
       "2  03LZVFM6    0.914904  0.026605  0.031895  0.026596"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summition = pd.DataFrame(y_prob, columns =nb.classes_)\n",
    "summition['ID'] = test['ID']\n",
    "summition = summition[['ID', 'Depression', 'Alcohol' ,'Suicide' ,'Drugs']]\n",
    "summition.to_csv(r\"F:\\Challenge\\NeedsRights_Kenya\\res\\submission_nb.csv\", index=False)\n",
    "summition.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.001,\n",
       "                                                                     average=False,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     early_stopping=False,\n",
       "                                                                     epsilon=0.1,\n",
       "                                                                     eta0=0.0,\n",
       "                                                                     fit_intercept=True,\n",
       "                                                                     l1_ratio=0.15,\n",
       "                                                                     learning_rate='optimal',\n",
       "                                                                     loss='hinge',\n",
       "                                                                     max_iter=5,\n",
       "                                                                     n_iter_no_change=5,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     penalty='l2',\n",
       "                                                                     power_t=0.5,\n",
       "                                                                     random_state=42,\n",
       "                                                                     shuffle=True,\n",
       "                                                                     tol=None,\n",
       "                                                                     validation_fraction=0.1,\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False),\n",
       "                                        cv='warn', method='sigmoid'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', CalibratedClassifierCV(base_estimator=SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))),\n",
    "               ])\n",
    "sgd.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8378378378378378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Alcohol       0.88      0.84      0.86        43\n",
      "  Depression       0.82      0.95      0.88        95\n",
      "       Drugs       1.00      0.68      0.81        22\n",
      "     Suicide       0.74      0.56      0.64        25\n",
      "\n",
      "    accuracy                           0.84       185\n",
      "   macro avg       0.86      0.76      0.80       185\n",
      "weighted avg       0.84      0.84      0.83       185\n",
      "\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18808806, 0.71384504, 0.02098314, 0.07708376],\n",
       "       [0.0272229 , 0.9196932 , 0.01284513, 0.04023877],\n",
       "       [0.00402335, 0.97668747, 0.00871782, 0.01057135],\n",
       "       ...,\n",
       "       [0.16279646, 0.43872036, 0.07050492, 0.32797826],\n",
       "       [0.00217919, 0.03863266, 0.90936342, 0.04982474],\n",
       "       [0.71109067, 0.17384727, 0.03087803, 0.08418403]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"F:\\Challenge\\NeedsRights_Kenya\\data\\Test.csv\", sep=\",\")\n",
    "y_prob = sgd.predict_proba(test['text'])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.713845</td>\n",
       "      <td>0.188088</td>\n",
       "      <td>0.077084</td>\n",
       "      <td>0.020983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.919693</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.012845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.008718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Depression   Alcohol   Suicide     Drugs\n",
       "0  02V56KMO    0.713845  0.188088  0.077084  0.020983\n",
       "1  03BMGTOK    0.919693  0.027223  0.040239  0.012845\n",
       "2  03LZVFM6    0.976687  0.004023  0.010571  0.008718"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summition = pd.DataFrame(y_prob, columns =sgd.classes_)\n",
    "summition['ID'] = test['ID']\n",
    "summition = summition[['ID', 'Depression', 'Alcohol' ,'Suicide' ,'Drugs']]\n",
    "summition.to_csv(r\"F:\\Challenge\\NeedsRights_Kenya\\res\\submission_sgd.csv\", index=False)\n",
    "summition.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Alcohol       0.76      0.87      0.81        30\n",
      "  Depression       0.70      0.93      0.80        30\n",
      "       Drugs       1.00      0.83      0.91        30\n",
      "     Suicide       0.71      0.50      0.59        30\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.79      0.78      0.78       120\n",
      "weighted avg       0.79      0.78      0.78       120\n",
      "\n",
      "Wall time: 25.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec embedding and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(r\"F:\\Challenge\\NeedsRights_Kenya\\resources\\GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common way is to average the two word vectors. BOW based approaches which includes averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['label'])\n",
    "y_pred = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Alcohol       0.84      0.88      0.86        43\n",
      "  Depression       0.85      0.85      0.85        95\n",
      "       Drugs       0.80      0.73      0.76        22\n",
      "     Suicide       0.52      0.52      0.52        25\n",
      "\n",
      "    accuracy                           0.80       185\n",
      "   macro avg       0.75      0.75      0.75       185\n",
      "weighted avg       0.80      0.80      0.80       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, test.label))\n",
    "print(classification_report(test.label, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 431\n",
      "Test size: 185\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(df) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posts = df['text'][:train_size]\n",
    "train_tags = df['label'][:train_size]\n",
    "\n",
    "test_posts = df['text'][train_size:]\n",
    "test_tags = df['label'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (431, 1000)\n",
      "x_test shape: (185, 1000)\n",
      "y_train shape: (431, 4)\n",
      "y_test shape: (185, 4)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0506 20:34:35.571188 821804 deprecation_wrapper.py:119] From C:\\Users\\Soubeiga Armel\\Documents\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 387 samples, validate on 44 samples\n",
      "Epoch 1/5\n",
      "387/387 [==============================] - ETA: 15s - loss: 1.3828 - accuracy: 0.187 - ETA: 7s - loss: 1.3767 - accuracy: 0.218 - ETA: 4s - loss: 1.3664 - accuracy: 0.29 - ETA: 3s - loss: 1.3550 - accuracy: 0.35 - ETA: 2s - loss: 1.3385 - accuracy: 0.42 - ETA: 1s - loss: 1.3334 - accuracy: 0.44 - ETA: 1s - loss: 1.3225 - accuracy: 0.47 - ETA: 1s - loss: 1.3141 - accuracy: 0.49 - ETA: 0s - loss: 1.3082 - accuracy: 0.50 - ETA: 0s - loss: 1.2936 - accuracy: 0.52 - ETA: 0s - loss: 1.2806 - accuracy: 0.53 - ETA: 0s - loss: 1.2693 - accuracy: 0.55 - 3s 7ms/step - loss: 1.2696 - accuracy: 0.5556 - val_loss: 1.2075 - val_accuracy: 0.5682\n",
      "Epoch 2/5\n",
      "387/387 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.65 - ETA: 0s - loss: 1.0772 - accuracy: 0.68 - ETA: 0s - loss: 1.0729 - accuracy: 0.68 - ETA: 0s - loss: 1.0401 - accuracy: 0.75 - ETA: 0s - loss: 1.0351 - accuracy: 0.73 - ETA: 0s - loss: 1.0353 - accuracy: 0.72 - ETA: 0s - loss: 1.0437 - accuracy: 0.70 - ETA: 0s - loss: 1.0388 - accuracy: 0.69 - ETA: 0s - loss: 1.0339 - accuracy: 0.69 - ETA: 0s - loss: 1.0204 - accuracy: 0.70 - ETA: 0s - loss: 1.0061 - accuracy: 0.70 - ETA: 0s - loss: 1.0103 - accuracy: 0.69 - 1s 2ms/step - loss: 1.0081 - accuracy: 0.6977 - val_loss: 1.0903 - val_accuracy: 0.5455\n",
      "Epoch 3/5\n",
      "387/387 [==============================] - ETA: 0s - loss: 1.0724 - accuracy: 0.50 - ETA: 0s - loss: 0.8898 - accuracy: 0.67 - ETA: 0s - loss: 0.8390 - accuracy: 0.70 - ETA: 0s - loss: 0.8329 - accuracy: 0.71 - ETA: 0s - loss: 0.8110 - accuracy: 0.72 - ETA: 0s - loss: 0.8124 - accuracy: 0.71 - ETA: 0s - loss: 0.8156 - accuracy: 0.71 - ETA: 0s - loss: 0.8230 - accuracy: 0.70 - ETA: 0s - loss: 0.8099 - accuracy: 0.71 - ETA: 0s - loss: 0.8115 - accuracy: 0.71 - ETA: 0s - loss: 0.8093 - accuracy: 0.71 - 1s 2ms/step - loss: 0.8085 - accuracy: 0.7132 - val_loss: 1.0268 - val_accuracy: 0.5909\n",
      "Epoch 4/5\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.7700 - accuracy: 0.65 - ETA: 0s - loss: 0.7470 - accuracy: 0.68 - ETA: 0s - loss: 0.7433 - accuracy: 0.70 - ETA: 0s - loss: 0.7279 - accuracy: 0.71 - ETA: 0s - loss: 0.7195 - accuracy: 0.72 - ETA: 0s - loss: 0.7147 - accuracy: 0.72 - ETA: 0s - loss: 0.7128 - accuracy: 0.71 - ETA: 0s - loss: 0.7116 - accuracy: 0.72 - ETA: 0s - loss: 0.6871 - accuracy: 0.73 - ETA: 0s - loss: 0.6615 - accuracy: 0.75 - ETA: 0s - loss: 0.6639 - accuracy: 0.75 - ETA: 0s - loss: 0.6637 - accuracy: 0.75 - 1s 3ms/step - loss: 0.6596 - accuracy: 0.7545 - val_loss: 0.9804 - val_accuracy: 0.6364\n",
      "Epoch 5/5\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.78 - ETA: 1s - loss: 0.5639 - accuracy: 0.75 - ETA: 0s - loss: 0.5877 - accuracy: 0.75 - ETA: 0s - loss: 0.5761 - accuracy: 0.76 - ETA: 0s - loss: 0.5505 - accuracy: 0.78 - ETA: 0s - loss: 0.5779 - accuracy: 0.77 - ETA: 0s - loss: 0.5852 - accuracy: 0.76 - ETA: 0s - loss: 0.5877 - accuracy: 0.76 - ETA: 0s - loss: 0.5815 - accuracy: 0.76 - ETA: 0s - loss: 0.5699 - accuracy: 0.77 - ETA: 0s - loss: 0.5566 - accuracy: 0.78 - 1s 2ms/step - loss: 0.5564 - accuracy: 0.7829 - val_loss: 0.9330 - val_accuracy: 0.6591\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - ETA:  - ETA:  - 0s 591us/step\n",
      "Test accuracy: 0.6864864826202393\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7652045968416575, 0.6864864826202393]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
